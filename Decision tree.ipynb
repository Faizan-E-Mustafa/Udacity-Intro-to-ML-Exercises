{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if you want to know more about  preprocess function go to this link \n",
    "https://github.com/Faizan-E-Mustafa/Udacity-Intro-to-ML-Exercises/blob/master/Naive%20bayes%20(Additional%20learning%20resources%20included).ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/faizan/.virtualenvs/keras_tf/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import cross_validation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "def preprocess(per, words_file = \"tools/word_data.pkl\", authors_file=\"tools/email_authors.pkl\"):\n",
    "    \"\"\" \n",
    "        this function takes a pre-made list of email texts (by default word_data.pkl)\n",
    "        and the corresponding authors (by default email_authors.pkl) and performs\n",
    "        a number of preprocessing steps:\n",
    "            -- splits into training/testing sets (10% testing)\n",
    "            -- vectorizes into tfidf matrix\n",
    "            -- selects/keeps most helpful features\n",
    "\n",
    "        after this, the feaures and labels are put into numpy arrays, which play nice with sklearn functions\n",
    "\n",
    "        4 objects are returned:\n",
    "            -- training/testing features\n",
    "            -- training/testing labels\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    ### the words (features) and authors (labels), already largely preprocessed\n",
    "    ### this preprocessing will be repeated in the text learning mini-project\n",
    "    authors_file_handler = open(authors_file, \"rb\")\n",
    "    authors = pickle.load(authors_file_handler)\n",
    "    authors_file_handler.close()\n",
    "\n",
    "    words_file_handler = open(words_file, \"rb\")\n",
    "    word_data = pickle.load(words_file_handler)\n",
    "    words_file_handler.close()\n",
    "\n",
    "    ### test_size is the percentage of events assigned to the test set\n",
    "    ### (remainder go into training)\n",
    "    features_train, features_test, labels_train, labels_test = cross_validation.train_test_split(word_data, authors, test_size= 0.14, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "    ### text vectorization--go from strings to lists of numbers\n",
    "    vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5,\n",
    "                                 stop_words='english')\n",
    "    features_train_transformed = vectorizer.fit_transform(features_train)\n",
    "    #print(vectorizer.vocabulary_)\n",
    "    #print(vectorizer.idf_)\n",
    "    \n",
    "    features_test_transformed  = vectorizer.transform(features_test)\n",
    "\n",
    "\n",
    "\n",
    "    ### feature selection, because text is super high dimensional and \n",
    "    ### can be really computationally chewy as a result\n",
    "    selector = SelectPercentile(f_classif, percentile=per)\n",
    "    selector.fit(features_train_transformed, labels_train)\n",
    "    features_train_transformed = selector.transform(features_train_transformed).toarray()\n",
    "    features_test_transformed  = selector.transform(features_test_transformed).toarray()\n",
    "\n",
    "    ### info on the data\n",
    "    print (\"no. of Chris training emails:\", sum(labels_train))\n",
    "    print (\"no. of Sara training emails:\", len(labels_train)-sum(labels_train))\n",
    "    \n",
    "    \n",
    "    return features_train_transformed, features_test_transformed, labels_train, labels_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Q1 :find the number of features in your data.  The data is organized into a numpy array where the number of rows is the number of data points and the number of columns is the number of features; so to extract this number, use a line of code like len(features_train[0])\n",
    "\n",
    "find the line of code that looks like this:     selector = SelectPercentile(f_classif, percentile=1)  Change percentile from 10 to 1.\n",
    "\n",
    "* Q2: What’s the number of features now?\n",
    "\n",
    "\n",
    "* Q3: What do you think SelectPercentile is doing?  Would a large value for percentile lead to a more complex or less complex decis , all other things being equal?\n",
    "  \n",
    "  \n",
    "* Q4: What’s the accuracy when percentile = 1?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decion tree with percentile=10\n",
      "no. of Chris training emails: 7571\n",
      "no. of Sara training emails: 7546\n",
      "training time: 115.316 s\n",
      "test time: 0.074 s\n",
      "accuracy percentile=10: 0.982933766761479\n",
      "Q1: 3749\n",
      "Decion tree with percentile=1\n",
      "no. of Chris training emails: 7571\n",
      "no. of Sara training emails: 7546\n",
      "training time: 8.092 s\n",
      "test time: 0.004 s\n",
      "Q2: 375\n",
      "Q3: large values percentile will select large numbr of features and large numbr of features result in a more complex decion tree which is more prone to overfitting\n",
      "Q4:accuracy percentile=1: 0.9650548557496953\n"
     ]
    }
   ],
   "source": [
    "# decision tree\n",
    "\n",
    "### features_train and features_test are the features for the training\n",
    "### and testing datasets, respectively\n",
    "### labels_train and labels_test are the corresponding item labels\n",
    "print(\"Decion tree with percentile=10\")\n",
    "features_train, features_test, labels_train, labels_test = preprocess(per = 10)\n",
    "from time import time\n",
    "from sklearn import tree\n",
    "\n",
    "\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(min_samples_split=40)\n",
    "\n",
    "t0 = time()\n",
    "clf.fit(features_train,labels_train)\n",
    "print (\"training time:\", round(time()-t0, 3), \"s\")\n",
    "\n",
    "t0 = time()\n",
    "pred = clf.predict(features_test)\n",
    "print (\"test time:\", round(time()-t0, 3), \"s\")\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(pred, labels_test)\n",
    "print(\"accuracy percentile=10:\",acc)\n",
    "\n",
    "\n",
    "print(\"Q1:\", len(features_train[0]))\n",
    "\n",
    "print(\"Decion tree with percentile=1\")\n",
    "\n",
    "features_train, features_test, labels_train, labels_test = preprocess(per = 1)\n",
    "clf = tree.DecisionTreeClassifier(min_samples_split=40)\n",
    "\n",
    "t0 = time()\n",
    "clf.fit(features_train,labels_train)\n",
    "print (\"training time:\", round(time()-t0, 3), \"s\")\n",
    "\n",
    "t0 = time()\n",
    "pred = clf.predict(features_test)\n",
    "print (\"test time:\", round(time()-t0, 3), \"s\")\n",
    "\n",
    "\n",
    "acc = accuracy_score(pred, labels_test)\n",
    "\n",
    "\n",
    "print(\"Q2:\", len(features_train[0]))\n",
    "print(\"Q3:\", \"large values percentile will select large numbr of features and large numbr of features result in a more complex decion tree which is more prone to overfitting\")\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(pred, labels_test)\n",
    "print(\"Q4:accuracy percentile=1:\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
